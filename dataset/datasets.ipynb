{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets Module\n",
    "\n",
    "Ce notebook contient l'implémentation des classes Dataset et DataLoader pour le projet M2 AMIS.\n",
    "\n",
    "## Structure:\n",
    "1. **BaseDataset** - Classe abstraite de base (comme PyTorch)\n",
    "2. **MoleculeDataset** - Dataset pour les molécules ChEBI\n",
    "3. **SyntheticDataset** - Dataset synthétique généré\n",
    "4. **DataLoader** - Pour itérer sur les datasets\n",
    "5. **DatasetFactory** - Pour créer facilement des datasets"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:15.114986Z",
     "start_time": "2026-02-01T18:52:15.091990Z"
    }
   },
   "source": [
    "from abc import ABC, abstractmethod\n",
    "from typing import List, Tuple, Optional, Iterator, Callable, Any, Dict, Union\n",
    "from dataclasses import dataclass, field\n",
    "import random\n",
    "import itertools\n",
    "from collections.abc import Iterable"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Base Dataset Class\n",
    "\n",
    "Inspiré de `torch.utils.data.Dataset`"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:15.522085Z",
     "start_time": "2026-02-01T18:52:15.428152Z"
    }
   },
   "source": [
    "class BaseDataset(ABC):\n",
    "    \"\"\"\n",
    "    Classe abstraite de base pour tous les datasets.\n",
    "    \"\"\"\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __len__(self) -> int:\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def __getitem__(self, index: int):\n",
    "        pass\n",
    "    \n",
    "    def __iter__(self) -> Iterator:\n",
    "        for i in range(len(self)):\n",
    "            yield self[i]\n",
    "    \n",
    "    def get_metadata(self) -> Dict[str, Any]:\n",
    "        return {\n",
    "            \"type\": self.__class__.__name__,\n",
    "            \"size\": len(self)\n",
    "        }"
   ],
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Molecule Dataset\n",
    "\n",
    "Dataset pour stocker des molécules (intégration avec MoleculeGraph d'Ethan)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:16.082430Z",
     "start_time": "2026-02-01T18:52:15.965015Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class MoleculeEntry:\n",
    "    \"\"\"\n",
    "    Entrée représentant une molécule dans le dataset.\n",
    "    Attributes:\n",
    "        chebi_id: Identifiant ChEBI de la molécule\n",
    "        graph: Le graphe de la molécule (MoleculeGraph)\n",
    "        name: Nom de la molécule (optionnel)\n",
    "        properties: Propriétés additionnelles\n",
    "    \"\"\"\n",
    "    chebi_id: str\n",
    "    graph: Any\n",
    "    name: Optional[str] = None\n",
    "    properties: Dict[str, Any] = field(default_factory=dict)\n",
    "    \n",
    "    def __hash__(self):\n",
    "        return hash(self.chebi_id)\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        if isinstance(other, MoleculeEntry):\n",
    "            return self.chebi_id == other.chebi_id\n",
    "        return False"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:16.729801Z",
     "start_time": "2026-02-01T18:52:16.285262Z"
    }
   },
   "source": [
    "class MoleculeDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Dataset contenant des molécules.\n",
    "    Peut être créé:\n",
    "    - À partir d'une liste de ChEBI IDs\n",
    "    - À partir de fichiers mol locaux\n",
    "    - À partir d'un filtrage par propriétés\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        molecules: Optional[List[MoleculeEntry]] = None,\n",
    "        name: str = \"unnamed_dataset\"\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initialise le dataset.\n",
    "        \"\"\"\n",
    "        self._molecules: List[MoleculeEntry] = molecules or []\n",
    "        self._name = name\n",
    "        self._index_map: Dict[str, int] = {}\n",
    "        self._rebuild_index()\n",
    "    \n",
    "    def _rebuild_index(self):\n",
    "        \"\"\"Reconstruit l'index chebi_id -> position.\"\"\"\n",
    "        self._index_map = {mol.chebi_id: i for i, mol in enumerate(self._molecules)}\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._molecules)\n",
    "    \n",
    "    def __getitem__(self, index: Union[int, str]) -> MoleculeEntry:\n",
    "        \"\"\"\n",
    "        Récupère une molécule par index ou par chebi_id.\n",
    "        \"\"\"\n",
    "        if isinstance(index, str):\n",
    "            if index not in self._index_map:\n",
    "                raise KeyError(f\"Molecule with chebi_id '{index}' not found\")\n",
    "            return self._molecules[self._index_map[index]]\n",
    "        return self._molecules[index]\n",
    "    \n",
    "    def add_molecule(self, molecule: MoleculeEntry):\n",
    "        \"\"\"Ajoute une molécule au dataset.\"\"\"\n",
    "        if molecule.chebi_id in self._index_map:\n",
    "            raise ValueError(f\"Molecule {molecule.chebi_id} already exists\")\n",
    "        self._index_map[molecule.chebi_id] = len(self._molecules)\n",
    "        self._molecules.append(molecule)\n",
    "    \n",
    "    def remove_molecule(self, chebi_id: str):\n",
    "        \"\"\"Retire une molécule du dataset.\"\"\"\n",
    "        if chebi_id not in self._index_map:\n",
    "            raise KeyError(f\"Molecule {chebi_id} not found\")\n",
    "        idx = self._index_map[chebi_id]\n",
    "        self._molecules.pop(idx)\n",
    "        self._rebuild_index()\n",
    "    \n",
    "    def filter(self, predicate: Callable[[MoleculeEntry], bool]) -> 'MoleculeDataset':\n",
    "        \"\"\"\n",
    "        Filtre le dataset selon un prédicat.\n",
    "        \"\"\"\n",
    "        filtered = [mol for mol in self._molecules if predicate(mol)]\n",
    "        return MoleculeDataset(filtered, name=f\"{self._name}_filtered\")\n",
    "    \n",
    "    def get_all_chebi_ids(self) -> List[str]:\n",
    "        \"\"\"Retourne tous les ChEBI IDs.\"\"\"\n",
    "        return list(self._index_map.keys())\n",
    "    \n",
    "    def get_pairs(self, include_self: bool = False) -> Iterator[Tuple[MoleculeEntry, MoleculeEntry]]:\n",
    "        \"\"\"\n",
    "        Génère toutes les paires de molécules.\n",
    "        \"\"\"\n",
    "        if include_self:\n",
    "            return itertools.combinations_with_replacement(self._molecules, 2)\n",
    "        return itertools.combinations(self._molecules, 2)\n",
    "    \n",
    "    def get_metadata(self) -> Dict[str, Any]:\n",
    "        base = super().get_metadata()\n",
    "        base.update({\n",
    "            \"name\": self._name,\n",
    "            \"chebi_ids\": self.get_all_chebi_ids()\n",
    "        })\n",
    "        return base\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"MoleculeDataset(name='{self._name}', size={len(self)})\""
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Pair Dataset\n",
    "\n",
    "Dataset spécialisé pour les paires de molécules (utile pour les tests d'isomorphisme)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:17.154509Z",
     "start_time": "2026-02-01T18:52:16.909884Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class MoleculePair:\n",
    "    \"\"\"\n",
    "    Représente une paire de molécules avec un label optionnel.\n",
    "    Attributes:\n",
    "        mol1: Première molécule\n",
    "        mol2: Deuxième molécule\n",
    "        is_isomorphic: Label indiquant si les molécules sont isomorphes (pour ground truth)\n",
    "        similarity: Score de similarité (optionnel)\n",
    "    \"\"\"\n",
    "    mol1: MoleculeEntry\n",
    "    mol2: MoleculeEntry\n",
    "    is_isomorphic: Optional[bool] = None\n",
    "    similarity: Optional[float] = None\n",
    "\n",
    "\n",
    "class PairDataset(BaseDataset):\n",
    "    \"\"\"\n",
    "    Dataset de paires de molécules.\n",
    "    Utile pour le benchmarking des algorithmes d'isomorphisme.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pairs: Optional[List[MoleculePair]] = None,\n",
    "        name: str = \"unnamed_pair_dataset\"\n",
    "    ):\n",
    "        self._pairs = pairs or []\n",
    "        self._name = name\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        return len(self._pairs)\n",
    "    \n",
    "    def __getitem__(self, index: int) -> MoleculePair:\n",
    "        return self._pairs[index]\n",
    "    \n",
    "    def add_pair(self, pair: MoleculePair):\n",
    "        self._pairs.append(pair)\n",
    "    \n",
    "    @classmethod\n",
    "    def from_molecule_dataset(\n",
    "        cls,\n",
    "        dataset: MoleculeDataset,\n",
    "        include_self: bool = False\n",
    "    ) -> 'PairDataset':\n",
    "        \"\"\"\n",
    "        Crée un PairDataset à partir d'un MoleculeDataset.\n",
    "        Génère toutes les paires possibles.\n",
    "        \"\"\"\n",
    "        pairs = [\n",
    "            MoleculePair(mol1, mol2)\n",
    "            for mol1, mol2 in dataset.get_pairs(include_self)\n",
    "        ]\n",
    "        return cls(pairs, name=f\"{dataset._name}_pairs\")\n",
    "    \n",
    "    def get_positive_pairs(self) -> List[MoleculePair]:\n",
    "        return [p for p in self._pairs if p.is_isomorphic is True]\n",
    "    \n",
    "    def get_negative_pairs(self) -> List[MoleculePair]:\n",
    "        return [p for p in self._pairs if p.is_isomorphic is False]\n",
    "    \n",
    "    def get_metadata(self) -> Dict[str, Any]:\n",
    "        base = super().get_metadata()\n",
    "        base.update({\n",
    "            \"name\": self._name,\n",
    "            \"num_positive\": len(self.get_positive_pairs()),\n",
    "            \"num_negative\": len(self.get_negative_pairs())\n",
    "        })\n",
    "        return base"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Synthetic Dataset Generator\n",
    "\n",
    "Génération de datasets synthétiques avec contrôle sur les propriétés"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:17.292764Z",
     "start_time": "2026-02-01T18:52:17.265445Z"
    }
   },
   "source": [
    "@dataclass\n",
    "class SyntheticDatasetConfig:\n",
    "    \"\"\"\n",
    "    Configuration pour la génération de datasets synthétiques.\n",
    "    \n",
    "    Attributes:\n",
    "        num_molecules: Nombre de molécules à générer\n",
    "        min_atoms: Nombre minimum d'atomes\n",
    "        max_atoms: Nombre maximum d'atomes\n",
    "        atom_types: Types d'atomes possibles\n",
    "        bond_types: Types de liaisons possibles\n",
    "        connectivity: Degré de connectivité (0.0 à 1.0)\n",
    "        seed: Graine aléatoire pour reproductibilité\n",
    "        include_isomorphic_pairs: Générer des paires isomorphes connues\n",
    "        num_isomorphic_pairs: Nombre de paires isomorphes à générer\n",
    "    \"\"\"\n",
    "    num_molecules: int = 100\n",
    "    min_atoms: int = 3\n",
    "    max_atoms: int = 20\n",
    "    atom_types: List[str] = field(default_factory=lambda: [\"C\", \"H\", \"O\", \"N\", \"S\", \"P\"])\n",
    "    bond_types: List[str] = field(default_factory=lambda: [\"1\", \"2\", \"3\"])  # single, double, triple\n",
    "    connectivity: float = 0.3\n",
    "    seed: Optional[int] = None\n",
    "    include_isomorphic_pairs: bool = True\n",
    "    num_isomorphic_pairs: int = 10"
   ],
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:17.716187Z",
     "start_time": "2026-02-01T18:52:17.531395Z"
    }
   },
   "source": [
    "class SyntheticMoleculeGenerator:\n",
    "    \"\"\"\n",
    "    Générateur de molécules synthétiques.\n",
    "    Permet de créer des graphes moléculaires artificiels\n",
    "    avec des propriétés contrôlées.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, config: SyntheticDatasetConfig):\n",
    "        self.config = config\n",
    "        if config.seed is not None:\n",
    "            random.seed(config.seed)\n",
    "    \n",
    "    def _generate_single_molecule(self, mol_id: str) -> MoleculeEntry:\n",
    "        \"\"\"\n",
    "        Génère une molécule synthétique aléatoire.\n",
    "\n",
    "        \"\"\"\n",
    "        num_atoms = random.randint(self.config.min_atoms, self.config.max_atoms)\n",
    "\n",
    "        nodes = []\n",
    "        for i in range(num_atoms):\n",
    "            atom_type = random.choice(self.config.atom_types)\n",
    "            nodes.append({\"id\": i + 1, \"color\": atom_type})\n",
    "\n",
    "        edges = []\n",
    "        for i in range(1, num_atoms):\n",
    "            j = random.randint(0, i - 1)\n",
    "            bond_type = random.choice(self.config.bond_types)\n",
    "            edges.append({\"u\": j + 1, \"v\": i + 1, \"color\": bond_type})\n",
    "\n",
    "        max_additional = int(num_atoms * (num_atoms - 1) / 2 - (num_atoms - 1))\n",
    "        num_additional = int(max_additional * self.config.connectivity)\n",
    "        existing_edges = set((min(e[\"u\"], e[\"v\"]), max(e[\"u\"], e[\"v\"])) for e in edges)\n",
    "        \n",
    "        for _ in range(num_additional):\n",
    "            attempts = 0\n",
    "            while attempts < 10:\n",
    "                i = random.randint(1, num_atoms)\n",
    "                j = random.randint(1, num_atoms)\n",
    "                if i != j and (min(i, j), max(i, j)) not in existing_edges:\n",
    "                    bond_type = random.choice(self.config.bond_types)\n",
    "                    edges.append({\"u\": i, \"v\": j, \"color\": bond_type})\n",
    "                    existing_edges.add((min(i, j), max(i, j)))\n",
    "                    break\n",
    "                attempts += 1\n",
    "\n",
    "        graph_data = {\"nodes\": nodes, \"edges\": edges}\n",
    "        \n",
    "        return MoleculeEntry(\n",
    "            chebi_id=f\"SYNTHETIC_{mol_id}\",\n",
    "            graph=graph_data,\n",
    "            name=f\"Synthetic Molecule {mol_id}\",\n",
    "            properties={\n",
    "                \"num_atoms\": num_atoms,\n",
    "                \"num_bonds\": len(edges),\n",
    "                \"is_synthetic\": True\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def _create_isomorphic_copy(self, original: MoleculeEntry, new_id: str) -> MoleculeEntry:\n",
    "        \"\"\"\n",
    "        Crée une copie isomorphe d'une molécule (permutation des noeuds).\n",
    "        \"\"\"\n",
    "        graph_data = original.graph\n",
    "        nodes = graph_data[\"nodes\"]\n",
    "        edges = graph_data[\"edges\"]\n",
    "        old_ids = [n[\"id\"] for n in nodes]\n",
    "        new_ids = old_ids.copy()\n",
    "        random.shuffle(new_ids)\n",
    "        id_mapping = dict(zip(old_ids, new_ids))\n",
    "        new_nodes = [{\"id\": id_mapping[n[\"id\"]], \"color\": n[\"color\"]} for n in nodes]\n",
    "        new_edges = [{\"u\": id_mapping[e[\"u\"]], \"v\": id_mapping[e[\"v\"]], \"color\": e[\"color\"]} for e in edges]\n",
    "        \n",
    "        return MoleculeEntry(\n",
    "            chebi_id=f\"SYNTHETIC_{new_id}\",\n",
    "            graph={\"nodes\": new_nodes, \"edges\": new_edges},\n",
    "            name=f\"Synthetic Molecule {new_id} (isomorphic to {original.chebi_id})\",\n",
    "            properties={\n",
    "                **original.properties,\n",
    "                \"isomorphic_to\": original.chebi_id\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    def generate_dataset(self) -> Tuple[MoleculeDataset, PairDataset]:\n",
    "        \"\"\"\n",
    "        Génère un dataset synthétique complet.\n",
    "        \"\"\"\n",
    "        molecules = []\n",
    "        isomorphic_pairs = []\n",
    "        base_count = self.config.num_molecules\n",
    "        if self.config.include_isomorphic_pairs:\n",
    "            base_count -= self.config.num_isomorphic_pairs\n",
    "        \n",
    "        for i in range(base_count):\n",
    "            mol = self._generate_single_molecule(str(i))\n",
    "            molecules.append(mol)\n",
    "\n",
    "        if self.config.include_isomorphic_pairs:\n",
    "            for i in range(self.config.num_isomorphic_pairs):\n",
    "                original = random.choice(molecules[:base_count])\n",
    "                iso_copy = self._create_isomorphic_copy(original, f\"ISO_{i}\")\n",
    "                molecules.append(iso_copy)\n",
    "                isomorphic_pairs.append(MoleculePair(\n",
    "                    mol1=original,\n",
    "                    mol2=iso_copy,\n",
    "                    is_isomorphic=True\n",
    "                ))\n",
    "\n",
    "        mol_dataset = MoleculeDataset(molecules, name=\"synthetic_dataset\")\n",
    "        pair_dataset = PairDataset(isomorphic_pairs, name=\"synthetic_pairs_ground_truth\")\n",
    "        \n",
    "        return mol_dataset, pair_dataset"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. DataLoader\n",
    "\n",
    "Pour itérer sur les datasets avec batching et shuffling"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:17.961071Z",
     "start_time": "2026-02-01T18:52:17.936929Z"
    }
   },
   "source": [
    "class DataLoader:\n",
    "    \"\"\"\n",
    "    DataLoader pour itérer sur les datasets.\n",
    "    Supporte le batching et le shuffling.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        dataset: BaseDataset,\n",
    "        batch_size: int = 1,\n",
    "        shuffle: bool = False,\n",
    "        drop_last: bool = False\n",
    "    ):\n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.drop_last = drop_last\n",
    "    \n",
    "    def __len__(self) -> int:\n",
    "        if self.drop_last:\n",
    "            return len(self.dataset) // self.batch_size\n",
    "        return (len(self.dataset) + self.batch_size - 1) // self.batch_size\n",
    "    \n",
    "    def __iter__(self) -> Iterator[List]:\n",
    "        indices = list(range(len(self.dataset)))\n",
    "        \n",
    "        if self.shuffle:\n",
    "            random.shuffle(indices)\n",
    "        \n",
    "        batch = []\n",
    "        for idx in indices:\n",
    "            batch.append(self.dataset[idx])\n",
    "            if len(batch) == self.batch_size:\n",
    "                yield batch\n",
    "                batch = []\n",
    "        \n",
    "        if batch and not self.drop_last:\n",
    "            yield batch"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Dataset Factory\n",
    "\n",
    "Création facile de datasets à partir de différentes sources"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.115120Z",
     "start_time": "2026-02-01T18:52:18.048980Z"
    }
   },
   "source": [
    "class DatasetFactory:\n",
    "    \"\"\"\n",
    "    Factory pour créer des datasets facilement.\n",
    "    Méthodes statiques pour créer des datasets à partir de:\n",
    "    - Liste de ChEBI IDs\n",
    "    - Fichiers mol locaux\n",
    "    - Configuration synthétique\n",
    "    - Filtres sur propriétés\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_chebi_ids(\n",
    "        chebi_ids: List[str],\n",
    "        name: str = \"chebi_dataset\",\n",
    "        chebi_retriever=None\n",
    "    ) -> MoleculeDataset:\n",
    "        \"\"\"\n",
    "        Crée un dataset à partir d'une liste de ChEBI IDs.\n",
    "        \"\"\"\n",
    "        molecules = []\n",
    "        \n",
    "        for chebi_id in chebi_ids:\n",
    "            try:\n",
    "                # mol_text = chebi_retriever.get_mol(chebi_id)\n",
    "                # graph = MoleculeGraph.from_moltext(mol_text)\n",
    "\n",
    "                mol_entry = MoleculeEntry(\n",
    "                    chebi_id=chebi_id,\n",
    "                    graph=None,\n",
    "                    properties={\"source\": \"chebi\"}\n",
    "                )\n",
    "                molecules.append(mol_entry)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load molecule {chebi_id}: {e}\")\n",
    "        \n",
    "        return MoleculeDataset(molecules, name=name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def from_mol_files(\n",
    "        file_paths: List[str],\n",
    "        name: str = \"local_dataset\"\n",
    "    ) -> MoleculeDataset:\n",
    "        \"\"\"\n",
    "        Crée un dataset à partir de fichiers mol locaux.\n",
    "        \"\"\"\n",
    "        molecules = []\n",
    "        \n",
    "        for i, path in enumerate(file_paths):\n",
    "            try:\n",
    "                import os\n",
    "                filename = os.path.basename(path)\n",
    "                mol_id = filename.replace(\".mol\", \"\")\n",
    "                \n",
    "                mol_entry = MoleculeEntry(\n",
    "                    chebi_id=mol_id,\n",
    "                    graph=None,\n",
    "                    properties={\"source\": \"local\", \"file_path\": path}\n",
    "                )\n",
    "                molecules.append(mol_entry)\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not load file {path}: {e}\")\n",
    "        \n",
    "        return MoleculeDataset(molecules, name=name)\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_synthetic(\n",
    "        config: Optional[SyntheticDatasetConfig] = None,\n",
    "        **kwargs\n",
    "    ) -> Tuple[MoleculeDataset, PairDataset]:\n",
    "        \"\"\"\n",
    "        Crée un dataset synthétique.\n",
    "        \"\"\"\n",
    "        if config is None:\n",
    "            config = SyntheticDatasetConfig(**kwargs)\n",
    "        \n",
    "        generator = SyntheticMoleculeGenerator(config)\n",
    "        return generator.generate_dataset()\n",
    "    \n",
    "    @staticmethod\n",
    "    def create_benchmark_dataset(\n",
    "        num_small: int = 50,\n",
    "        num_medium: int = 30,\n",
    "        num_large: int = 20,\n",
    "        seed: int = 42\n",
    "    ) -> MoleculeDataset:\n",
    "        \"\"\"\n",
    "        Crée un dataset de benchmark avec différentes tailles de molécules.\n",
    "        \"\"\"\n",
    "        all_molecules = []\n",
    "        \n",
    "        # Petites molécules\n",
    "        small_config = SyntheticDatasetConfig(\n",
    "            num_molecules=num_small,\n",
    "            min_atoms=3,\n",
    "            max_atoms=10,\n",
    "            seed=seed,\n",
    "            include_isomorphic_pairs=False\n",
    "        )\n",
    "        small_gen = SyntheticMoleculeGenerator(small_config)\n",
    "        small_ds, _ = small_gen.generate_dataset()\n",
    "        for mol in small_ds:\n",
    "            mol.properties[\"size_category\"] = \"small\"\n",
    "            all_molecules.append(mol)\n",
    "        \n",
    "        # Molécules moyennes\n",
    "        medium_config = SyntheticDatasetConfig(\n",
    "            num_molecules=num_medium,\n",
    "            min_atoms=10,\n",
    "            max_atoms=30,\n",
    "            seed=seed + 1,\n",
    "            include_isomorphic_pairs=False\n",
    "        )\n",
    "        medium_gen = SyntheticMoleculeGenerator(medium_config)\n",
    "        medium_ds, _ = medium_gen.generate_dataset()\n",
    "        for mol in medium_ds:\n",
    "            mol.properties[\"size_category\"] = \"medium\"\n",
    "            mol.chebi_id = mol.chebi_id.replace(\"SYNTHETIC_\", \"SYNTHETIC_MED_\")\n",
    "            all_molecules.append(mol)\n",
    "        \n",
    "        # Grandes molécules\n",
    "        large_config = SyntheticDatasetConfig(\n",
    "            num_molecules=num_large,\n",
    "            min_atoms=30,\n",
    "            max_atoms=50,\n",
    "            seed=seed + 2,\n",
    "            include_isomorphic_pairs=False\n",
    "        )\n",
    "        large_gen = SyntheticMoleculeGenerator(large_config)\n",
    "        large_ds, _ = large_gen.generate_dataset()\n",
    "        for mol in large_ds:\n",
    "            mol.properties[\"size_category\"] = \"large\"\n",
    "            mol.chebi_id = mol.chebi_id.replace(\"SYNTHETIC_\", \"SYNTHETIC_LRG_\")\n",
    "            all_molecules.append(mol)\n",
    "        \n",
    "        return MoleculeDataset(all_molecules, name=\"benchmark_dataset\")"
   ],
   "outputs": [],
   "execution_count": 10
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Exemples d'utilisation"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.176983Z",
     "start_time": "2026-02-01T18:52:18.144051Z"
    }
   },
   "source": [
    "print(\"Exemple 1: Dataset synthétique simple\")\n",
    "\n",
    "config = SyntheticDatasetConfig(\n",
    "    num_molecules=20,\n",
    "    min_atoms=5,\n",
    "    max_atoms=15,\n",
    "    seed=42,\n",
    "    include_isomorphic_pairs=True,\n",
    "    num_isomorphic_pairs=5\n",
    ")\n",
    "\n",
    "mol_dataset, pair_dataset = DatasetFactory.create_synthetic(config)\n",
    "print(f\"Dataset créé: {mol_dataset}\")\n",
    "print(f\"Paires avec ground truth: {len(pair_dataset)}\")\n",
    "print(f\"Métadonnées: {mol_dataset.get_metadata()}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 1: Dataset synthétique simple\n",
      "Dataset créé: MoleculeDataset(name='synthetic_dataset', size=20)\n",
      "Paires avec ground truth: 5\n",
      "Métadonnées: {'type': 'MoleculeDataset', 'size': 20, 'name': 'synthetic_dataset', 'chebi_ids': ['SYNTHETIC_0', 'SYNTHETIC_1', 'SYNTHETIC_2', 'SYNTHETIC_3', 'SYNTHETIC_4', 'SYNTHETIC_5', 'SYNTHETIC_6', 'SYNTHETIC_7', 'SYNTHETIC_8', 'SYNTHETIC_9', 'SYNTHETIC_10', 'SYNTHETIC_11', 'SYNTHETIC_12', 'SYNTHETIC_13', 'SYNTHETIC_14', 'SYNTHETIC_ISO_0', 'SYNTHETIC_ISO_1', 'SYNTHETIC_ISO_2', 'SYNTHETIC_ISO_3', 'SYNTHETIC_ISO_4']}\n"
     ]
    }
   ],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.331445Z",
     "start_time": "2026-02-01T18:52:18.303261Z"
    }
   },
   "source": [
    "print(\"Exemple 2: Utilisation du DataLoader\")\n",
    "\n",
    "loader = DataLoader(mol_dataset, batch_size=4, shuffle=True)\n",
    "\n",
    "print(f\"Nombre de batches: {len(loader)}\")\n",
    "for i, batch in enumerate(loader):\n",
    "    print(f\"Batch {i}: {len(batch)} molécules\")\n",
    "    if i >= 2:\n",
    "        print(\"...\")\n",
    "        break"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 2: Utilisation du DataLoader\n",
      "Nombre de batches: 5\n",
      "Batch 0: 4 molécules\n",
      "Batch 1: 4 molécules\n",
      "Batch 2: 4 molécules\n",
      "...\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.471428Z",
     "start_time": "2026-02-01T18:52:18.460124Z"
    }
   },
   "source": [
    "print(\"Exemple 3: Filtrage du dataset\")\n",
    "large_mols = mol_dataset.filter(\n",
    "    lambda mol: mol.properties.get(\"num_atoms\", 0) > 10\n",
    ")\n",
    "print(f\"Molécules originales: {len(mol_dataset)}\")\n",
    "print(f\"Molécules filtrées (>10 atomes): {len(large_mols)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 3: Filtrage du dataset\n",
      "Molécules originales: 20\n",
      "Molécules filtrées (>10 atomes): 6\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.626280Z",
     "start_time": "2026-02-01T18:52:18.584821Z"
    }
   },
   "source": [
    "print(\"Exemple 4: Dataset de benchmark\")\n",
    "benchmark_ds = DatasetFactory.create_benchmark_dataset(\n",
    "    num_small=30,\n",
    "    num_medium=20,\n",
    "    num_large=10,\n",
    "    seed=123\n",
    ")\n",
    "print(f\"Dataset benchmark: {benchmark_ds}\")\n",
    "small = benchmark_ds.filter(lambda m: m.properties.get(\"size_category\") == \"small\")\n",
    "medium = benchmark_ds.filter(lambda m: m.properties.get(\"size_category\") == \"medium\")\n",
    "large = benchmark_ds.filter(lambda m: m.properties.get(\"size_category\") == \"large\")\n",
    "\n",
    "print(f\"  - Petites: {len(small)}\")\n",
    "print(f\"  - Moyennes: {len(medium)}\")\n",
    "print(f\"  - Grandes: {len(large)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 4: Dataset de benchmark\n",
      "Dataset benchmark: MoleculeDataset(name='benchmark_dataset', size=60)\n",
      "  - Petites: 30\n",
      "  - Moyennes: 20\n",
      "  - Grandes: 10\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.702186Z",
     "start_time": "2026-02-01T18:52:18.690187Z"
    }
   },
   "source": [
    "print(\"Exemple 5: Génération de paires\")\n",
    "small_ds, ground_truth = DatasetFactory.create_synthetic(\n",
    "    num_molecules=10,\n",
    "    include_isomorphic_pairs=True,\n",
    "    num_isomorphic_pairs=3,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "all_pairs = PairDataset.from_molecule_dataset(small_ds)\n",
    "print(f\"Molécules: {len(small_ds)}\")\n",
    "print(f\"Paires totales: {len(all_pairs)}\")\n",
    "print(f\"Paires isomorphes connues: {len(ground_truth)}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemple 5: Génération de paires\n",
      "Molécules: 10\n",
      "Paires totales: 45\n",
      "Paires isomorphes connues: 3\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Intégration avec le code existant\n",
    "\n",
    "Voici comment intégrer avec le code d'Ethan (MoleculeGraph)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.854888Z",
     "start_time": "2026-02-01T18:52:18.848741Z"
    }
   },
   "source": [
    "\"\"\"\n",
    "from graph import MoleculeGraph, Node, Edge\n",
    "from Chebi.CheBi import Chebi\n",
    "\n",
    "def create_molecule_entry_from_chebi(chebi_id: str, retriever: Chebi) -> MoleculeEntry:\n",
    "    '''Crée un MoleculeEntry à partir d'un ChEBI ID.'''\n",
    "    mol_text = retriever.get_mol(chebi_id)\n",
    "    graph = MoleculeGraph.from_moltext(mol_text)\n",
    "    \n",
    "    return MoleculeEntry(\n",
    "        chebi_id=chebi_id,\n",
    "        graph=graph,\n",
    "        properties={\n",
    "            \"num_atoms\": len(graph.nodes),\n",
    "            \"num_bonds\": sum(len(edges) for edges in graph.edges.values()) // 2,\n",
    "            \"num_diff_atoms\": graph.getNbDiffAtome(),\n",
    "            \"num_diff_bonds\": graph.getNbDiffLink()\n",
    "        }\n",
    "    )\n",
    "\n",
    "# Exemple d'utilisation:\n",
    "# retriever = Chebi(\"chebi_cache.db\")\n",
    "# entry = create_molecule_entry_from_chebi(\"136874\", retriever)\n",
    "\"\"\"\n",
    "print(\"Code d'intégration prêt (décommenter quand les imports sont disponibles)\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code d'intégration prêt (décommenter quand les imports sont disponibles)\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Export des classes pour utilisation dans le projet"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2026-02-01T18:52:18.934531Z",
     "start_time": "2026-02-01T18:52:18.920575Z"
    }
   },
   "source": [
    "__all__ = [\n",
    "    'BaseDataset',\n",
    "    'MoleculeEntry',\n",
    "    'MoleculeDataset',\n",
    "    'MoleculePair',\n",
    "    'PairDataset',\n",
    "    'SyntheticDatasetConfig',\n",
    "    'SyntheticMoleculeGenerator',\n",
    "    'DataLoader',\n",
    "    'DatasetFactory'\n",
    "]\n",
    "\n",
    "print(\"Classes disponibles:\")\n",
    "for cls in __all__:\n",
    "    print(f\"  - {cls}\")"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes disponibles:\n",
      "  - BaseDataset\n",
      "  - MoleculeEntry\n",
      "  - MoleculeDataset\n",
      "  - MoleculePair\n",
      "  - PairDataset\n",
      "  - SyntheticDatasetConfig\n",
      "  - SyntheticMoleculeGenerator\n",
      "  - DataLoader\n",
      "  - DatasetFactory\n"
     ]
    }
   ],
   "execution_count": 17
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
